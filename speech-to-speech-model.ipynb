{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements in alphabetical order:\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import playsound\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, AutoTokenizer\n",
    "from whisper_mic import WhisperMic\n",
    "from gtts import gTTS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device and torch dtype for the model on the GPU\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2102f6a0c23641a28f8dc9026f1e7b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/24 22:04:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No mic index provided, using default                                 <a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#84\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">84</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/24 22:04:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No mic index provided, using default                                 \u001b]8;id=194789;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=496155;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/24 22:04:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Mic setup complete                                                   <a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/24 22:04:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Mic setup complete                                                   \u001b]8;id=702771;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=947818;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Listening<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                        <a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#214\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening\u001b[33m...\u001b[0m                                                        \u001b]8;id=414982;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=748291;file://c:\\Users\\harsh\\anaconda3\\envs\\development\\lib\\site-packages\\whisper_mic\\whisper_mic.py#214\u001b\\\u001b[2m214\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the full form of WWG whole cell banking? Can you elaborate more about whole cell banking?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    mic = WhisperMic()\n",
    "    result = mic.listen()\n",
    "    print(result)\n",
    "    promptinput = result\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWG stands for Whole-Cell Banking. Whole-cell banking is a process in which cell lines, cultures, or organisms are stored for future use. This involves preserving living cells or organisms under highly controlled conditions to maintain their viability and functionality for an extended period.\n",
      "\n",
      "Whole-cell banking is crucial in various fields, including biotechnology, pharmaceuticals, and regenerative medicine. By preserving cell lines, researchers can ensure consistency in their experiments, have a backup in case of contamination or loss of cells, and facilitate the reproducibility of results.\n",
      "\n",
      "The process of whole-cell banking typically involves the following steps:\n",
      "1. Cell line authentication and characterization: Confirming the identity and characteristics of the cell line before storing it.\n",
      "2. Cell culture preparation: Growing the cells under suitable conditions to ensure their health and viability.\n",
      "3. Cryopreservation: Freezing the cells at ultra-low temperatures, usually in liquid nitrogen, to halt their biological activities and extend their shelf life.\n",
      "4. Storage and management: Managing the frozen cell banks in specialized facilities equipped with stringent quality controls to prevent contamination and maintain the cells' integrity.\n",
      "5. Thawing and revival: Thawing the cells when needed and carefully reviving them to ensure they retain their original characteristics.\n",
      "\n",
      "Overall, whole-cell banking plays a vital role in supporting scientific research, drug development, and other applications that rely on consistent and reliable cell-based systems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY2\"))\n",
    "\n",
    "\n",
    "question = promptinput\n",
    "\n",
    "# Call the OpenAI API to get a response to the user's question\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"assistant\", \"content\": \"You are a helpful assistant designed to answer user queries.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    ")\n",
    "t2tresult = completion.choices[0].message.content\n",
    "# Extract the generated text from the response\n",
    "print(t2tresult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text to audio\n",
    "\n",
    "tts = gTTS(text=t2tresult, lang='en')  # Replace 'en' with your desired language\n",
    "tts.save('output.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "t2ainput = t2tresult\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"nova\",\n",
    "  input=t2ainput\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0253d77b17224b5fb7588eacb762b1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "# as we are able to convert the speech to text, we can now use the text to text model\n",
    "\n",
    "\n",
    "t2tmodel=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(t2tmodel)\n",
    " # create Huggingface pipeline\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\",\n",
    "     model=t2tmodel,\n",
    "     tokenizer=tokenizer,\n",
    "     torch_dtype=torch.bfloat16,\n",
    "     trust_remote_code=True,\n",
    "     device_map=\"auto\",\n",
    "     max_length=1000,\n",
    "     do_sample=True,\n",
    "     top_k=10,\n",
    "     num_return_sequences=1,\n",
    "     eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-2-7b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "print(t2tmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x000002C77CAACD90>\n"
     ]
    }
   ],
   "source": [
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2tresult=llm.invoke(promptinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"Write a creative story about...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2tresult = llm.invoke(prompt=zero_shot_prompt,input=promptinput, model_kwargs={'temperature':0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A. Mumbai\n",
      "B. Delhi\n",
      "C. Kolkata\n",
      "D. Chennai\n",
      "\n",
      "Answer: B. Delhi\n",
      "\n",
      "Explanation: Delhi is the capital city of India.\n"
     ]
    }
   ],
   "source": [
    "print(t2tresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text to audio\n",
    "import playsound\n",
    "from gtts import gTTS\n",
    "tts = gTTS(text=t2tresult, lang='en')  # Replace 'en' with your desired language\n",
    "tts.save('output.mp3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio file\n",
    "playsound(\"generated_audio.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
